{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with Slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jk/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "\"\"\"A LeNet-5 like cnn MNIST classifier.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "train_labels = np.asarray(train_labels, dtype=np.int32)\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_labels = np.asarray(test_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST image check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = 500\n",
    "print(\"label = {}\".format(train_labels[index]))\n",
    "plt.imshow(train_data[index].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((?, 28, 28), (?,)), types: (tf.float64, tf.int32)>\n",
      "<BatchDataset shapes: ((?, 28, 28), (?,)), types: (tf.float64, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 10000)\n",
    "train_dataset = train_dataset.batch(batch_size = batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "test_dataset = test_dataset.shuffle(buffer_size = 10000)\n",
    "test_dataset = test_dataset.batch(batch_size = len(test_data))\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Iterator.from_string_handle의 output_shapes는 default = None이지만 꼭 값을 넣는 게 좋음\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle,\n",
    "                                               train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "x, y = iterator.get_next()\n",
    "x = tf.cast(x, dtype = tf.float32)\n",
    "y = tf.cast(y, dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(x):\n",
    "    \"\"\"Model function for CNN.\n",
    "    Args:\n",
    "    x: input images\n",
    "    mode: boolean whether trainig mode or test mode\n",
    "\n",
    "    Returns:\n",
    "    logits: unnormalized score funtion\n",
    "    \"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    # MNIST images are 28x28 pixels, and have one color channel\n",
    "    with tf.name_scope('reshape'):\n",
    "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    conv1 = slim.conv2d(x_image, 32, [5, 5], scope='conv1')\n",
    "    #conv1 = tf.layers.conv2d(\n",
    "    #    inputs=x_image,\n",
    "    #    filters=32,\n",
    "    #    kernel_size=[5, 5],\n",
    "    #    padding=\"same\",\n",
    "    #    activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    pool1 = slim.max_pool2d(conv1, [2, 2], scope='pool1')\n",
    "    #pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    conv2 = slim.conv2d(pool1, 64, [5, 5], scope='conv2')\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    pool2 = slim.max_pool2d(conv2, [2, 2], scope='pool2')\n",
    "\n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    pool2_flat = slim.flatten(pool2, scope='flatten')\n",
    "\n",
    "    # Fully connected Layer\n",
    "    # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    # Output Tensor Shape: [batch_size, 1024]\n",
    "    fc1 = slim.fully_connected(pool2_flat, 1024, scope='fc1')\n",
    "    #dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "    # Add dropout operation; 0.6 probability that element will be kept\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    fc1_drop = slim.dropout(fc1, keep_prob=0.6, is_training=is_training, scope='dropout')\n",
    "    #dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=is_training)\n",
    "\n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 1024]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    logits = slim.fully_connected(fc1_drop, 10, activation_fn=None, scope='logits')\n",
    "\n",
    "    return logits, is_training, x_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, is_training, x_image = cnn_model_fn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_one_hot = tf.one_hot(y, depth=10)\n",
    "#cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_one_hot, logits=logits)\n",
    "cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=y,\n",
    "                                                       logits=logits)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph to: graphs/02_mnist_cnn_with_slim\n"
     ]
    }
   ],
   "source": [
    "graph_location = 'graphs/02_mnist_cnn_with_slim'\n",
    "print('Saving graph to: %s' % graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(tf.get_default_graph()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "    tf.summary.scalar('loss/cross_entropy', cross_entropy)\n",
    "    tf.summary.image('images', x_image)\n",
    "    for var in tf.trainable_variables():\n",
    "        tf.summary.histogram(var.op.name, var)\n",
    "    # merge all summaries\n",
    "    summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 2.3054018020629883\n",
      "step: 100, loss: 0.7794369459152222\n",
      "step: 200, loss: 0.2645017206668854\n",
      "step: 300, loss: 0.19662272930145264\n",
      "step: 400, loss: 0.19276155531406403\n",
      "step: 500, loss: 0.2217557281255722\n",
      "step: 600, loss: 0.11127368360757828\n",
      "step: 700, loss: 0.15821143984794617\n",
      "step: 800, loss: 0.14743898808956146\n",
      "step: 900, loss: 0.1069193109869957\n",
      "step: 1000, loss: 0.08314377814531326\n",
      "step: 1100, loss: 0.05682499334216118\n",
      "step: 1200, loss: 0.05818236246705055\n",
      "step: 1300, loss: 0.11629575490951538\n",
      "step: 1400, loss: 0.10289282351732254\n",
      "step: 1500, loss: 0.27312472462654114\n",
      "step: 1600, loss: 0.38963639736175537\n",
      "step: 1700, loss: 0.03131403774023056\n",
      "step: 1800, loss: 0.13416926562786102\n",
      "End of dataset\n",
      "Epochs: 0 Elapsed time: 204.71409583091736\n",
      "training done!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train_iterator\n",
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "train_handle = sess.run(train_iterator.string_handle())\n",
    "\n",
    "# Train\n",
    "max_epochs = 1\n",
    "step = 0\n",
    "for epochs in range(max_epochs):\n",
    "    # 여기를 직접 채워 넣으시면 됩니다.\n",
    "    sess.run(train_iterator.initializer)\n",
    "\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            # 여기를 직접 채워 넣으시면 됩니다.\n",
    "            _, loss = sess.run([train_step, cross_entropy],\n",
    "                             feed_dict={handle: train_handle,\n",
    "                                        is_training: True})\n",
    "            if step % 100 == 0:\n",
    "                print(\"step: {}, loss: {}\".format(step, loss))\n",
    "\n",
    "                # summary\n",
    "                summary_str = sess.run(summary_op, feed_dict={handle: train_handle, is_training: False})\n",
    "                train_writer.add_summary(summary_str, global_step=step)\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of dataset\")  # ==> \"End of dataset\"\n",
    "            break\n",
    "\n",
    "    print(\"Epochs: {} Elapsed time: {}\".format(epochs, time.time() - start_time))\n",
    "\n",
    "train_writer.close()\n",
    "print(\"training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_iterator\n",
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "test_handle = sess.run(test_iterator.string_handle())\n",
    "sess.run(test_iterator.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, acc_op = tf.metrics.accuracy(labels=y, predictions=tf.argmax(logits, 1), name='accuracy')\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "sess.run(acc_op, feed_dict={handle: test_handle, is_training: False})\n",
    "print(\"test accuracy:\", sess.run(accuracy, feed_dict={handle: test_handle, is_training: False}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "test_batch_size = 16\n",
    "batch_index = np.random.choice(len(test_data), size=test_batch_size, replace=False)\n",
    "batch_xs = test_data[batch_index]\n",
    "y_pred = sess.run(logits, feed_dict={x: batch_xs, is_training: False})\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (px, py) in enumerate(zip(batch_xs, y_pred)):\n",
    "    p = fig.add_subplot(4, 8, i+1)\n",
    "    p.set_title(\"y_pred: {}\".format(np.argmax(py)))\n",
    "    p.imshow(px.reshape(28, 28), cmap='gray')\n",
    "    p.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
