{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jk/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras import backend as k\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "def save_history_history(fname, history_history, fold=''):\n",
    "    np.save(os.path.join(fold, fname), history_history)\n",
    "\n",
    "\n",
    "def load_history_history(fname, fold=''):\n",
    "    history_history = np.load(os.path.join(fold, fname)).item(0)\n",
    "    return history_history\n",
    "\n",
    "\n",
    "def plot_acc(history, title=None):\n",
    "    # summarize history for accuracy\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    plt.plot(history['acc'])\n",
    "    plt.plot(history['val_acc'])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.ylabel('Accracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training data', 'Validation data'], loc=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plot_loss(history, title=None):\n",
    "    # summarize history for loss\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training data', 'Validation data'], loc=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plot_acc(history)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_loss(history)\n",
    "\n",
    "    \n",
    "def plot_loss_acc(history):\n",
    "    plot_loss(history, '(a) Loss trajectory')\n",
    "    plt.show()            \n",
    "    plot_acc(history, '(b) Accracy trajectory')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_acc_loss(history):\n",
    "    plot_acc(history, '(a) Accracy trajectory')\n",
    "    plt.show()\n",
    "    plot_loss(history, '(b) Loss trajectory')\n",
    "    plt.show()            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "\n",
    "def unique_filename(type='uuid'):\n",
    "    if type == 'datetime':\n",
    "        filename = datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "    else:  # type == \"uuid\"\n",
    "        filename = str(uuid.uuid4())\n",
    "    return filename\n",
    "\n",
    "\n",
    "def makenewfold(prefix='output_', type='datetime'):\n",
    "    suffix = unique_filename('datetime')\n",
    "    foldname = 'output_' + suffix\n",
    "    os.makedirs(foldname)\n",
    "    return foldname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Model):\n",
    "    def __init__(model, nb_classes, in_shape=None):\n",
    "        model.nb_classess = nb_classes\n",
    "        model.in_shape = in_shape\n",
    "        model.build_model()\n",
    "        super().__init__(model.x, model.y)\n",
    "        model.compile()\n",
    "        \n",
    "    def build_model(model):\n",
    "        nb_classes = model.nb_classes\n",
    "        in_shape = model.in_shape\n",
    "        \n",
    "        x = Input(in_shape)\n",
    "        \n",
    "        h = Conv2D(32, kernel_size = (3, 3), activation = 'relu', input_shape = in_shape)(x)\n",
    "        \n",
    "        h = Conv2D(64, (3, 3), activation = 'relu')(h)\n",
    "        h = MaxPooling2D(pool_size=(2,2))(h)\n",
    "        h = MaxPooling2D(pool_size=(2,2))(h)\n",
    "        h = Dropout(0.25)(h)\n",
    "        h = Flatten()(h)\n",
    "        z_cl = h\n",
    "        \n",
    "        h = Dense(128, activation = 'relu')(h)\n",
    "        h = Dropout(0.5)(h)\n",
    "        z_fl = h\n",
    "        \n",
    "        y = Dense(nb_classes, activation = 'softmax', name = 'preds')(h)\n",
    "        \n",
    "        model.cl_part = Model(x, z_cl)\n",
    "        model.fl_part = Model(z, z_fl)\n",
    "        \n",
    "        model.x, model.y = x, y\n",
    "        \n",
    "    def compile(model):\n",
    "        Model.compile(model, loss = 'categorical_crossentropy', optimizer = 'adadelta', metrics = ['accuracy'])\n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self, X, y, nb_classes, scaling=True, test_size=0.2, random_state=0):\n",
    "        \n",
    "        self.X= X\n",
    "        self.add_channels()\n",
    "        \n",
    "        X = self.X\n",
    "        X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "        \n",
    "        print(X_train.shape, y_train.shape)\n",
    "        \n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        \n",
    "        if scaling:\n",
    "            scaler = MinMaxScaler()\n",
    "            n = X_train.shape[0]\n",
    "            X_train = scaler.fit_transform(X_train.reshape(n, -1)).reshape(X_train.shape)\n",
    "            \n",
    "            n = X_test.shape[0]\n",
    "            X_test = scaler.transform(X_test.reshape(n, -1)).reshape(X_test)\n",
    "            \n",
    "        print('X_train shape:', X_train.shape)\n",
    "        print(X_train.shape[0], 'train samples')\n",
    "        print(X_test.shape[0], 'test samples')\n",
    "        \n",
    "        Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "        Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "        \n",
    "        self.X_train, self.X_test = X_train, X_test\n",
    "        self.Y_train, self.Y_test = Y_train, Y_test\n",
    "        self.y_train, self.y_test = y_train, y_test\n",
    "        \n",
    "    def add_channels(self):\n",
    "        X = self.X\n",
    "        \n",
    "        if len(X.shape) == 3:\n",
    "            N, img_rows, img_cols = X.shape\n",
    "            \n",
    "            if k.image_dim_ordering() == 'th':\n",
    "                X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "                input_shape = (1, img_rows, img_cols)\n",
    "                \n",
    "            else:\n",
    "                X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "                input_shape = (img_rows, img_cols, 1)\n",
    "                \n",
    "        else:\n",
    "            input_shape = X.shape[1:]\n",
    "            \n",
    "        self.X = X\n",
    "        self.input_shape = input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine():\n",
    "    def __init__(self, X, y, nb_classes = 2, fig=True):\n",
    "        self.nb_classes = nb_classes\n",
    "        self.set_data(X, y)\n",
    "        self.set_model()\n",
    "        self.fig = fig\n",
    "        \n",
    "    def set_data(self, X, y):\n",
    "        nb_classes = self.nb_classes\n",
    "        self.data = Dataset(X, y, nb_classes)\n",
    "        print('data.input_shape', self.data.input_shape)\n",
    "        \n",
    "    def set_model(self):\n",
    "        nb_classes = self.nb_classes\n",
    "        data = self.data\n",
    "        self.model = CNN(nb_classes=nb_classes, in_shape=data.input_shape)\n",
    "        \n",
    "    def fit(self, epochs=10, batch_size=128, verbos=1):\n",
    "        data = self.data\n",
    "        model = self.model\n",
    "        \n",
    "        history = model.fit(data.X_train, data.Y_train, batch_size=batch_size, epochs = epochs, verbos = verbose,\n",
    "                           validation_data=(data.X_test, data.Y_test))\n",
    "        return history\n",
    "    \n",
    "    def run(self, epochs=100, batch_size=128, verbose=1):\n",
    "        data = self.data\n",
    "        model = self.model\n",
    "        fig = self.fig\n",
    "        \n",
    "        history = self.fit(epochs=epochs, batch_size=batch_size, verbose = 1)\n",
    "        \n",
    "        score = model.evaluate(data.X_test, data.Y_test, verbose=0)\n",
    "        \n",
    "        print('confusion matrix')\n",
    "    \n",
    "        Y_test_pred = model.predict(data.X_test, verbose=0)\n",
    "        y_test_pred = np.argmax(Y_test_pred, axis=1)\n",
    "        print(metrics.confusion_matrix(data.y_test, y_test_pred))\n",
    "        \n",
    "        print('test score:', score[0])\n",
    "        print('test accuracy:', score[1])\n",
    "        \n",
    "        suffix = unique_filename('datatime')\n",
    "        foldname = 'output_' + suffix\n",
    "        os.makedirs(foldname)\n",
    "        save_history_history('history_history.npy', history.history, fold=foldname)\n",
    "        model.save_weights(os.path.join(foldname, 'dl_model.h5'))\n",
    "        print(\"output result are saved in\", foldname)\n",
    "        \n",
    "        if fig:\n",
    "            plt.figure(figsize=(12,4))\n",
    "            plt.subplot(1,2,1)\n",
    "            plot_acc(history)\n",
    "            plt.subplot(1,2,2)\n",
    "            plot_loss(history)\n",
    "            plt.show()\n",
    "            \n",
    "        self.history = history\n",
    "        \n",
    "        return foldname\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets\n",
    "import keras\n",
    "assert keras.backend.image_data_format() == 'channels_last'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'X' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d3e31bc14350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMachine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMachine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-d3e31bc14350>\u001b[0m in \u001b[0;36mMachine\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-d3e31bc14350>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMachine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'X' and 'y'"
     ]
    }
   ],
   "source": [
    "\n",
    "class Machine(Machine):\n",
    "    def __init__(self):\n",
    "        (X, y), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "        super().__init__(X, y, nb_classes=10)\n",
    "        \n",
    "    def main():\n",
    "        m = Machine()\n",
    "        m.run()\n",
    "        \n",
    "    if __name__ == '__main__':\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
